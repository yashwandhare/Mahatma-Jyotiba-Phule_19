# Environment Variables for RAGex
# Copy this file to .env and configure your API keys

# ============================================
# LLM Provider Configuration
# ============================================

# Provider: groq or ollama
PROVIDER=groq

# Model name (depends on provider)
# Groq: llama-3.1-70b-versatile, mixtral-8x7b-32768
# Ollama: llama2, mistral, codellama, etc.
MODEL=llama-3.1-70b-versatile

# ============================================
# API Keys (Required for Groq)
# ============================================

# Get your key from: https://console.groq.com/keys
GROQ_API_KEY=your_groq_api_key_here

# ============================================
# Vector Database Configuration
# ============================================

# Path to ChromaDB storage directory
CHROMADB_PATH=./chromadb_data

# Collection name in ChromaDB
COLLECTION_NAME=ragex_docs

# ============================================
# Ollama Configuration (Optional)
# ============================================

# Ollama API base URL (uncomment if needed)
# OLLAMA_BASE_URL=http://localhost:11434

# ============================================
# Retrieval Settings (Optional)
# ============================================

# Number of document chunks to retrieve
# TOP_K=5

# Minimum similarity score (0.0 to 1.0)
# MIN_SIMILARITY=0.5

# ============================================
# Server Configuration (Optional)
# ============================================

# API server host and port (for uvicorn)
# HOST=0.0.0.0
# PORT=8000

# Enable debug mode (verbose logging)
# DEBUG=false

# ============================================
# File Processing (Optional)
# ============================================

# Maximum file size in MB
# MAX_FILE_SIZE_MB=50

# Chunk size for text splitting
# CHUNK_SIZE=1000

# Chunk overlap for context preservation
# CHUNK_OVERLAP=200
